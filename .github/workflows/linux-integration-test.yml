name: Linux Integration Test

on:
  push:
    branches: [ cli-test ]
  pull_request:
    branches: [ cli-test ]

jobs:
  test-linux:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Set up Rust
      uses: actions-rs/toolchain@v1
      with:
        profile: minimal
        toolchain: stable
        override: true

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y xvfb pulseaudio ffmpeg libasound2-dev libgtk-3-dev libwebkit2gtk-4.0-dev libavformat-dev libavfilter-dev libavdevice-dev x11-utils x11-apps xdotool openbox xterm fonts-liberation tesseract-ocr libtesseract-dev imagemagick fonts-dejavu sox libsox-fmt-all

    - name: Verify Tesseract installation
      run: |
        tesseract --version
        ldconfig -p | grep tesseract
        ls -l /usr/lib/x86_64-linux-gnu/libtesseract*

    - name: Build CLI
      run: cargo build --release

    - name: Set up virtual display with window manager
      run: |
        Xvfb :99 -ac -screen 0 1280x1024x24 &
        echo "DISPLAY=:99" >> $GITHUB_ENV
        sleep 3
        export DISPLAY=:99
        mkdir -p ~/.config/openbox
        echo '<openbox_config><menu><file>menu.xml</file></menu></openbox_config>' > ~/.config/openbox/rc.xml
        openbox --config-file ~/.config/openbox/rc.xml &
        sleep 3
        xterm -fa 'Liberation Mono' -fs 10 -e "while true; do echo 'Keeping xterm open'; sleep 60; done" &
        sleep 3
        xdpyinfo || echo "xdpyinfo failed"
        xrandr || echo "xrandr failed"
        xwininfo -root -children || echo "xwininfo failed"

    - name: Set up virtual audio
      run: |
        pulseaudio --start
        pactl load-module module-null-sink sink_name=virtual_speaker
        pactl load-module module-virtual-source source_name=virtual_mic

    - name: Run CLI and capture output
      run: |
        export DISPLAY=:99
        export SCREENPIPE_CAPTURE_METHOD=x11 # Force X11 capture method
        export PATH=$PATH:/usr/bin  # Ensure /usr/bin is in PATH
        export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/x86_64-linux-gnu  # Add Tesseract library path
        ./target/release/screenpipe --debug > screenpipe_output.log 2>&1 &
        SCREENPIPE_PID=$!
        echo $SCREENPIPE_PID > screenpipe.pid
        sleep 60  # Let screenpipe run for 60 seconds

    - name: Test OCR
      run: |
        # List available fonts
        convert -list font

        # Create a test image with known text using a standard font
        convert -size 300x100 xc:white -font DejaVu-Sans -pointsize 24 -fill black -draw "text 10,50 'Hello, Screenpipe OCR'" test_image.png

        # Display the image
        DISPLAY=:99 display test_image.png &
        DISPLAY_PID=$!

        # Give some time for screenpipe to capture and process the image
        sleep 20

        # Kill the display process
        kill $DISPLAY_PID

        # Wait a bit for processing to complete
        sleep 10

        # Check the logs for the OCR result
        if grep -qi "Hello, Screenpipe OCR" screenpipe_output.log; then
          echo "OCR test passed: Text was recognized"
        else
          echo "OCR test failed: Text was not recognized"
          echo "Last 100 lines of log:"
          tail -n 100 screenpipe_output.log
          exit 1
        fi

    - name: Test Audio Transcription
      run: |
        # Generate a test audio file with known speech using SoX
        sox -n test_audio_with_speech.wav synth 5 sine 1000 vol 0.1 \
          synth 5 sine 1000 vol 0 \
          synth 1 sine 1000 vol 0 pad 1 \
          synth 1 sine 1000 vol 0 pad 2 \
          synth 1 sine 1000 vol 0 pad 3 \
          synth 1 sine 1000 vol 0 pad 4

        # Add speech using SoX's 'splice' feature
        echo "Hello Screenpipe transcription" | \
        while IFS= read -r word; do
          sox test_audio_with_speech.wav test_audio_temp.wav \
            synth 1 sine 880 vol 0.5 splice 1 : newfile : restart
          mv test_audio_temp.wav test_audio_with_speech.wav
        done

        # Play the audio file through the virtual audio device
        paplay --device=virtual_speaker test_audio_with_speech.wav &

        # Give some time for screenpipe to capture and process the audio
        sleep 20

        # Check the logs for the transcription result
        if grep -qi "Hello Screenpipe transcription" screenpipe_output.log; then
          echo "Audio transcription test passed: Speech was recognized"
        else
          echo "Audio transcription test failed: Speech was not recognized"
          echo "Last 100 lines of log:"
          tail -n 100 screenpipe_output.log
          exit 1
        fi

    - name: Stop screenpipe
      run: |
        kill $(cat screenpipe.pid)
        sleep 5  # Give time for graceful shutdown

    - name: Check for crashes and expected behavior
      run: |
        echo "Checking log file..."
        echo "Last 100 lines of log:"
        tail -n 100 screenpipe_output.log
        if grep -q "panic" screenpipe_output.log; then
          echo "CLI crashed"
          exit 1
        fi
        if ! grep -q "Server starting on 127.0.0.1:3030" screenpipe_output.log; then
          echo "Server did not start correctly"
          exit 1
        fi
        if grep -q "No windows found" screenpipe_output.log; then
          echo "No windows were detected"
          exit 1
        fi
        if grep -q "tesseract not found" screenpipe_output.log; then
          echo "Tesseract OCR not found"
          exit 1
        fi
        echo "CLI ran successfully without crashing"

    - name: Upload logs
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: screenpipe-logs
        path: screenpipe_output.log

    - name: Upload captured data
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: screenpipe-data
        path: ~/.screenpipe/data/

    - name: Upload test image
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-image
        path: test_image.png

    - name: Upload test audio
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-audio
        path: test_audio_with_speech.wav
